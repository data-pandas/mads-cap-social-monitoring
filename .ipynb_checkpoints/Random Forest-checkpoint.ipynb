{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80432a35",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "783351c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import sklearn.externals as extjoblib\n",
    "import joblib\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#from google.cloud import storage\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd50e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d67b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = pd.read_csv('cleaned_non-vectorized_data.csv')\n",
    "df_proc = df_proc[~df_proc['Text'].isna()]\n",
    "X = df_proc['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b64f5ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>disgust</th>\n",
       "      <th>joy</th>\n",
       "      <th>anger</th>\n",
       "      <th>surprised</th>\n",
       "      <th>sad</th>\n",
       "      <th>fear</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>come mert â€™ today let u take care lunch enjoy ...</td>\n",
       "      <td>['come', 'mert', 'â€™', 'today', 'let', 'u', 'ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nxt gt lay 20 staff tech 's latest cutback rb_...</td>\n",
       "      <td>['nxt', 'gt', 'lay', '20', 'staff', 'tech', \"'...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>layoff 20 workforce 100 employee sf bay area h...</td>\n",
       "      <td>['layoff', '20', 'workforce', '100', 'employee...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today â€™ lunch special smoked pork sausage onio...</td>\n",
       "      <td>['today', 'â€™', 'lunch', 'special', 'smoked', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>come mert â€™ today grab salmon cake two home co...</td>\n",
       "      <td>['come', 'mert', 'â€™', 'today', 'grab', 'salmon...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9277</th>\n",
       "      <td>traik01 cdc people warmed u 2 year ago .... sa...</td>\n",
       "      <td>['traik01', 'cdc', 'people', 'warmed', 'u', '2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9278</th>\n",
       "      <td>sorry â€™ promo code share lately ðŸ˜­ promos autom...</td>\n",
       "      <td>['sorry', 'â€™', 'promo', 'code', 'share', 'late...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9279</th>\n",
       "      <td>poor lad http //t.co/36o565zsc3</td>\n",
       "      <td>['poor', 'lad', 'http', '//t.co/36o565zsc3']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9280</th>\n",
       "      <td>one day able bill order tmobile bill sadly tod...</td>\n",
       "      <td>['one', 'day', 'able', 'bill', 'order', 'tmobi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9281</th>\n",
       "      <td>someone please bless dinner ðŸ¥¹</td>\n",
       "      <td>['someone', 'please', 'bless', 'dinner', '\\U00...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9279 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0     come mert â€™ today let u take care lunch enjoy ...   \n",
       "1     nxt gt lay 20 staff tech 's latest cutback rb_...   \n",
       "2     layoff 20 workforce 100 employee sf bay area h...   \n",
       "3     today â€™ lunch special smoked pork sausage onio...   \n",
       "4     come mert â€™ today grab salmon cake two home co...   \n",
       "...                                                 ...   \n",
       "9277  traik01 cdc people warmed u 2 year ago .... sa...   \n",
       "9278  sorry â€™ promo code share lately ðŸ˜­ promos autom...   \n",
       "9279                    poor lad http //t.co/36o565zsc3   \n",
       "9280  one day able bill order tmobile bill sadly tod...   \n",
       "9281                      someone please bless dinner ðŸ¥¹   \n",
       "\n",
       "                                                 tokens  disgust  joy  anger  \\\n",
       "0     ['come', 'mert', 'â€™', 'today', 'let', 'u', 'ta...        0    0      0   \n",
       "1     ['nxt', 'gt', 'lay', '20', 'staff', 'tech', \"'...        0    0      0   \n",
       "2     ['layoff', '20', 'workforce', '100', 'employee...        0    0      0   \n",
       "3     ['today', 'â€™', 'lunch', 'special', 'smoked', '...        0    0      0   \n",
       "4     ['come', 'mert', 'â€™', 'today', 'grab', 'salmon...        0    0      0   \n",
       "...                                                 ...      ...  ...    ...   \n",
       "9277  ['traik01', 'cdc', 'people', 'warmed', 'u', '2...        0    0      0   \n",
       "9278  ['sorry', 'â€™', 'promo', 'code', 'share', 'late...        0    0      0   \n",
       "9279       ['poor', 'lad', 'http', '//t.co/36o565zsc3']        0    0      0   \n",
       "9280  ['one', 'day', 'able', 'bill', 'order', 'tmobi...        0    0      0   \n",
       "9281  ['someone', 'please', 'bless', 'dinner', '\\U00...        0    0      0   \n",
       "\n",
       "      surprised  sad  fear  neutral  \n",
       "0             0    0     0        1  \n",
       "1             0    0     0        1  \n",
       "2             0    0     0        1  \n",
       "3             0    0     0        1  \n",
       "4             0    0     0        1  \n",
       "...         ...  ...   ...      ...  \n",
       "9277          0    1     0        0  \n",
       "9278          0    1     0        0  \n",
       "9279          0    1     0        0  \n",
       "9280          0    1     0        0  \n",
       "9281          0    1     0        0  \n",
       "\n",
       "[9279 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5790027",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_proc.loc[:,['disgust', 'joy', 'anger', 'surprised', 'sad', 'fear', 'neutral']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8644eb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disgust</th>\n",
       "      <th>joy</th>\n",
       "      <th>anger</th>\n",
       "      <th>surprised</th>\n",
       "      <th>sad</th>\n",
       "      <th>fear</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9277</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9278</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9279</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9280</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9281</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9279 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      disgust  joy  anger  surprised  sad  fear  neutral\n",
       "0           0    0      0          0    0     0        1\n",
       "1           0    0      0          0    0     0        1\n",
       "2           0    0      0          0    0     0        1\n",
       "3           0    0      0          0    0     0        1\n",
       "4           0    0      0          0    0     0        1\n",
       "...       ...  ...    ...        ...  ...   ...      ...\n",
       "9277        0    0      0          0    1     0        0\n",
       "9278        0    0      0          0    1     0        0\n",
       "9279        0    0      0          0    1     0        0\n",
       "9280        0    0      0          0    1     0        0\n",
       "9281        0    0      0          0    1     0        0\n",
       "\n",
       "[9279 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27baaeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827c76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1,2), min_df=50)\n",
    "transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a3063c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=RANDOM_SEED, \n",
    "                             #max_features='log2',\n",
    "                             #class_weight='balanced'\n",
    "                            )\n",
    "multi_out_clf = MultiOutputClassifier(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37cb859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the features and fit them to the classifier\n",
    "# multi_out_clf.fit(transformer.fit_transform(vectorizer.fit_transform(X_train)), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3109db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('transformer', transformer),\n",
    "    ('multi-classifier', multi_out_clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e3b7e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"vectorizer__max_df\": (0.5, 0.75, 1.0),\n",
    "    'vectorizer__max_features': (None, 5000, 10000, 50000),\n",
    "    \"vectorizer__ngram_range\": ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'transformer__use_idf': (True, False),\n",
    "    'transformer__norm': ('l1', 'l2'),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e672d097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'vectorizer', 'transformer', 'multi-classifier', 'vectorizer__analyzer', 'vectorizer__binary', 'vectorizer__decode_error', 'vectorizer__dtype', 'vectorizer__encoding', 'vectorizer__input', 'vectorizer__lowercase', 'vectorizer__max_df', 'vectorizer__max_features', 'vectorizer__min_df', 'vectorizer__ngram_range', 'vectorizer__preprocessor', 'vectorizer__stop_words', 'vectorizer__strip_accents', 'vectorizer__token_pattern', 'vectorizer__tokenizer', 'vectorizer__vocabulary', 'transformer__norm', 'transformer__smooth_idf', 'transformer__sublinear_tf', 'transformer__use_idf', 'multi-classifier__estimator__ccp_alpha', 'multi-classifier__estimator__class_weight', 'multi-classifier__estimator__criterion', 'multi-classifier__estimator__max_depth', 'multi-classifier__estimator__max_features', 'multi-classifier__estimator__max_leaf_nodes', 'multi-classifier__estimator__min_impurity_decrease', 'multi-classifier__estimator__min_impurity_split', 'multi-classifier__estimator__min_samples_leaf', 'multi-classifier__estimator__min_samples_split', 'multi-classifier__estimator__min_weight_fraction_leaf', 'multi-classifier__estimator__random_state', 'multi-classifier__estimator__splitter', 'multi-classifier__estimator', 'multi-classifier__n_jobs'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fceb888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vectorizer',\n",
       "                                        CountVectorizer(min_df=50,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        stop_words='english')),\n",
       "                                       ('transformer', TfidfTransformer()),\n",
       "                                       ('multi-classifier',\n",
       "                                        MultiOutputClassifier(estimator=DecisionTreeClassifier(random_state=42)))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'transformer__norm': ('l1', 'l2'),\n",
       "                         'transformer__use_idf': (True, False),\n",
       "                         'vectorizer__max_df': (0.5, 0.75, 1.0),\n",
       "                         'vectorizer__max_features': (None, 5000, 10000, 50000),\n",
       "                         'vectorizer__ngram_range': ((1, 1), (1, 2))},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7ecb566",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea3e13a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vectorizer',\n",
       "   CountVectorizer(max_df=0.75, min_df=50, ngram_range=(1, 2),\n",
       "                   stop_words='english')),\n",
       "  ('transformer', TfidfTransformer(norm='l1', use_idf=False)),\n",
       "  ('multi-classifier',\n",
       "   MultiOutputClassifier(estimator=DecisionTreeClassifier(random_state=42)))],\n",
       " 'verbose': False,\n",
       " 'vectorizer': CountVectorizer(max_df=0.75, min_df=50, ngram_range=(1, 2),\n",
       "                 stop_words='english'),\n",
       " 'transformer': TfidfTransformer(norm='l1', use_idf=False),\n",
       " 'multi-classifier': MultiOutputClassifier(estimator=DecisionTreeClassifier(random_state=42)),\n",
       " 'vectorizer__analyzer': 'word',\n",
       " 'vectorizer__binary': False,\n",
       " 'vectorizer__decode_error': 'strict',\n",
       " 'vectorizer__dtype': numpy.int64,\n",
       " 'vectorizer__encoding': 'utf-8',\n",
       " 'vectorizer__input': 'content',\n",
       " 'vectorizer__lowercase': True,\n",
       " 'vectorizer__max_df': 0.75,\n",
       " 'vectorizer__max_features': None,\n",
       " 'vectorizer__min_df': 50,\n",
       " 'vectorizer__ngram_range': (1, 2),\n",
       " 'vectorizer__preprocessor': None,\n",
       " 'vectorizer__stop_words': 'english',\n",
       " 'vectorizer__strip_accents': None,\n",
       " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vectorizer__tokenizer': None,\n",
       " 'vectorizer__vocabulary': None,\n",
       " 'transformer__norm': 'l1',\n",
       " 'transformer__smooth_idf': True,\n",
       " 'transformer__sublinear_tf': False,\n",
       " 'transformer__use_idf': False,\n",
       " 'multi-classifier__estimator__ccp_alpha': 0.0,\n",
       " 'multi-classifier__estimator__class_weight': None,\n",
       " 'multi-classifier__estimator__criterion': 'gini',\n",
       " 'multi-classifier__estimator__max_depth': None,\n",
       " 'multi-classifier__estimator__max_features': None,\n",
       " 'multi-classifier__estimator__max_leaf_nodes': None,\n",
       " 'multi-classifier__estimator__min_impurity_decrease': 0.0,\n",
       " 'multi-classifier__estimator__min_impurity_split': None,\n",
       " 'multi-classifier__estimator__min_samples_leaf': 1,\n",
       " 'multi-classifier__estimator__min_samples_split': 2,\n",
       " 'multi-classifier__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'multi-classifier__estimator__random_state': 42,\n",
       " 'multi-classifier__estimator__splitter': 'best',\n",
       " 'multi-classifier__estimator': DecisionTreeClassifier(random_state=42),\n",
       " 'multi-classifier__n_jobs': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a11b6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,roc_auc_score\n",
    "\n",
    "def print_classification_scores(y_test, pred):\n",
    "    print('Accuracy Score:',accuracy_score(y_test, pred))\n",
    "    print('Precision Score:',precision_score(y_test, pred, average='micro'))\n",
    "    print('Recall Score:',recall_score(y_test, pred, average='micro'))\n",
    "    print('F1 Score:',f1_score(y_test, pred, average='micro'))\n",
    "    print('AUC Score:',roc_auc_score(y_test, pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78fc5dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.4639008620689655\n",
      "Precision Score: 0.624432104997476\n",
      "Recall Score: 0.5834905660377359\n",
      "F1 Score: 0.6032674957327482\n",
      "AUC Score: 0.7575289474780291\n"
     ]
    }
   ],
   "source": [
    "pred = grid_search.predict(X_test)\n",
    "print_classification_scores(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca713f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff9d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
